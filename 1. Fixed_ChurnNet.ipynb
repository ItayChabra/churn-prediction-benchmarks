{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2BoEFIVyPEe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Add\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ftaVm2vvyth"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv(\"https://raw.githubusercontent.com/mahidul5130/ChurnNet_Deep_Learning_Enhanced_Customer_Churn-Prediction_in_Telecommunication_Industry/refs/heads/main/Churn-data-UCI%20Dataset(5000).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DYXdsCzQs2o"
      },
      "outputs": [],
      "source": [
        "Encoder = \"Label Encoder\"\n",
        "# Encoder = \"One-hot Encoder\"\n",
        "# OverSamplingTecnique = \"\"\n",
        "# OverSamplingTecnique = \"SMOTE-Tomek\"\n",
        "# OverSamplingTecnique = \"SMOTE-Enn\"\n",
        "\n",
        "# Let's try to use regular SMOTE instead of SMOTE-Enn\n",
        "OverSamplingTecnique = \"SMOTE\"\n",
        "\n",
        "filter_size=5\n",
        "number_of_filter=128\n",
        "flatten_layer_exist=True\n",
        "Model_Name=\"SE Block\"\n",
        "# Model_Name=\"Basic Channel Attention\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYrRuOWWDlGt"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeJgfRf2zQ8N",
        "outputId": "3ef62537-9993-40c4-ca61-0c7d6283c8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying Label Encoder\n",
            "Label Encoder Transformation\n",
            "internationalplan  :  [0 1]  =  [False  True]\n",
            "voicemailplan  :  [1 0]  =  [ True False]\n"
          ]
        }
      ],
      "source": [
        "if Encoder == \"Label Encoder\":\n",
        "  print(\"Applying Label Encoder\")\n",
        "  df_final = df_raw.copy()\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  text_data_features = ['internationalplan', 'voicemailplan']\n",
        "\n",
        "  print('Label Encoder Transformation')\n",
        "  for i in text_data_features :\n",
        "      df_final[i] = le.fit_transform(df_final[i])\n",
        "      print(i,' : ',df_final[i].unique(),' = ',le.inverse_transform(df_final[i].unique()))\n",
        "\n",
        "\n",
        "\n",
        "  X = df_final.drop(['churn'], axis=1).copy()\n",
        "  Y = df_final['churn'].copy().astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ane99tYEIOh"
      },
      "source": [
        "**One-hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv3ldE80D3ZE"
      },
      "outputs": [],
      "source": [
        "if Encoder == \"One-hot Encoder\":\n",
        "  print(\"Applying One-hot Encoder\")\n",
        "\n",
        "  # One-hot encode categorical columns\n",
        "  categorical_columns = ['internationalplan', 'voicemailplan']\n",
        "\n",
        "  encoder = OneHotEncoder()\n",
        "  encoded_features = encoder.fit_transform(df_raw[categorical_columns]).toarray()\n",
        "\n",
        "  # Combine one-hot encoded features with numerical features\n",
        "  numerical_features = df_raw.drop(categorical_columns + ['churn'], axis=1)\n",
        "  X = np.hstack((encoded_features, numerical_features))\n",
        "\n",
        "  # Manually encode 'Churn' column\n",
        "  # df_raw['Churn'] = df_raw['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "  # Extract the target variable Y\n",
        "  Y = df_raw['churn'].values\n",
        "\n",
        "\n",
        "  # Ensure all data is in float format\n",
        "  X = X.astype(float)\n",
        "  Y = Y.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgY86usCiVaw"
      },
      "source": [
        "**Squeeze-and-Excitation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z__CRDfozaXN"
      },
      "outputs": [],
      "source": [
        "# Define the channel attention layer\n",
        "class ChannelAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, reduction_ratio=8):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        self.fc = tf.keras.layers.Dense(channels // self.reduction_ratio, activation='relu')\n",
        "        self.attention = tf.keras.layers.Dense(channels, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.reduce_mean(inputs, axis=[1])  # Global average pooling across time dimension\n",
        "        x = self.fc(x)\n",
        "        x = self.attention(x)\n",
        "        x = tf.expand_dims(x, axis=1)  # Add a new dimension for broadcasting\n",
        "        return inputs * x\n",
        "\n",
        "# Define the spatial attention layer\n",
        "class SpatialAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=3, strides=1, padding='same')\n",
        "        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size=3, strides=1, padding='same')\n",
        "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
        "        self.conv1d = tf.keras.layers.Conv1D(filters=1, kernel_size=3, padding='same', activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        max_pool_out = self.max_pool(inputs)\n",
        "        avg_pool_out = self.avg_pool(inputs)\n",
        "        concat_out = self.concat([max_pool_out, avg_pool_out])\n",
        "        attention_weights = self.conv1d(concat_out)\n",
        "        return inputs * attention_weights\n",
        "\n",
        "\n",
        "# Define the residual block\n",
        "def residual_block(x, filters, kernel_size):\n",
        "    # Save the input tensor\n",
        "    x_shortcut = x\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = tf.keras.layers.Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = tf.keras.layers.Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n",
        "\n",
        "    # Add the shortcut connection\n",
        "    x = Add()([x, x_shortcut])\n",
        "\n",
        "    # Apply ReLU activation\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s15-s2sHiZZz"
      },
      "source": [
        "**Basic Channel Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8noScGii6qe"
      },
      "outputs": [],
      "source": [
        "# Define the channel attention layer for 1D data\n",
        "class Basic_ChannelAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, ratio=8):\n",
        "        super(Basic_ChannelAttention, self).__init__()\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, channels = input_shape[1:]\n",
        "        self.shared_layer1 = Conv1D(channels // self.ratio, kernel_size=1, activation='relu', padding='same')\n",
        "        self.shared_layer2 = Conv1D(channels, kernel_size=1, padding='same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
        "        x1 = self.shared_layer1(x1)\n",
        "        x1 = self.shared_layer2(x1)\n",
        "\n",
        "        x2 = tf.reduce_max(inputs, axis=1, keepdims=True)\n",
        "        x2 = self.shared_layer1(x2)\n",
        "        x2 = self.shared_layer2(x2)\n",
        "\n",
        "        attention = tf.add(x1, x2)\n",
        "        attention = Activation(\"sigmoid\")(attention)\n",
        "        output = Multiply()([inputs, attention])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9uxxru9zgU1"
      },
      "outputs": [],
      "source": [
        "def kfold_fixed(X, Y, filter_size, number_of_filter, flatten_layer_exist, Model_Name, OverSamplingTecnique):\n",
        "    print(\"Applying K-fold (Leak-Free)\")\n",
        "    print(f\"Applying {number_of_filter} filters of size {filter_size}\")\n",
        "\n",
        "    num_folds = 10\n",
        "\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    mcc_scores = []\n",
        "    auc_roc_scores = []\n",
        "\n",
        "    fold_number = 1\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_index, test_index in skf.split(X, Y):\n",
        "        print(f\"\\nFold {fold_number}/{num_folds}\")\n",
        "\n",
        "        # -------------------------\n",
        "        # 1. Split data\n",
        "        # -------------------------\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "        # -------------------------\n",
        "        # 2. Apply scaler ONLY on training data (Fixes leakage!)\n",
        "        # -------------------------\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # -------------------------\n",
        "        # 3. Apply SMOTE only to training data\n",
        "        # -------------------------\n",
        "        sampler = None\n",
        "        if OverSamplingTecnique == \"SMOTE\":\n",
        "            sampler = SMOTE(random_state=42)\n",
        "        elif OverSamplingTecnique == \"SMOTE-Tomek\":\n",
        "            sampler = SMOTETomek(random_state=42)\n",
        "        elif OverSamplingTecnique == \"SMOTE-Enn\":\n",
        "            sampler = SMOTEENN(random_state=42)\n",
        "\n",
        "        if sampler is not None:\n",
        "            print(f\"   Resampling training data with {OverSamplingTecnique}...\")\n",
        "            X_train, Y_train = sampler.fit_resample(X_train, Y_train)\n",
        "\n",
        "        # -------------------------\n",
        "        # 4. Reshape for Conv1D\n",
        "        # -------------------------\n",
        "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "        # -------------------------\n",
        "        # 5. Build the model\n",
        "        # -------------------------\n",
        "        inputs = tf.keras.Input(shape=(X_train.shape[1], 1))\n",
        "        x = tf.keras.layers.Conv1D(filters=number_of_filter, kernel_size=filter_size, activation='relu')(inputs)\n",
        "\n",
        "        x_res = residual_block(x, number_of_filter, filter_size)\n",
        "\n",
        "        if Model_Name == \"SE Block\":\n",
        "            x = ChannelAttention()(x_res)\n",
        "        else:\n",
        "            x = Basic_ChannelAttention()(x_res)\n",
        "\n",
        "        x = SpatialAttention()(x)\n",
        "        x = tf.keras.layers.Conv1D(filters=number_of_filter, kernel_size=filter_size, activation='relu', padding='same')(x)\n",
        "        x_res = residual_block(x, number_of_filter, filter_size)\n",
        "\n",
        "        if Model_Name == \"SE Block\":\n",
        "            x = ChannelAttention()(x_res)\n",
        "        else:\n",
        "            x = Basic_ChannelAttention()(x_res)\n",
        "\n",
        "        x = SpatialAttention()(x)\n",
        "\n",
        "        # if flatten_layer_exist:\n",
        "        #     x = tf.keras.layers.Flatten()(x)\n",
        "        # else:\n",
        "        #     x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "        # Only use GlobalAveragePooling1D, much better\n",
        "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(0.5)(x)\n",
        "        x = tf.keras.layers.Dense(number_of_filter, activation='relu')(x)\n",
        "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='ADAM', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # -------------------------\n",
        "        # 6. Train the model\n",
        "        # -------------------------\n",
        "\n",
        "        # Added early stopping, didnt exist in the original code.\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            monitor=\"val_loss\"\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train,\n",
        "            Y_train,\n",
        "            epochs=60, # Increased from 30\n",
        "            batch_size=32,\n",
        "            verbose=0,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping]\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # 7. Evaluate on PURE test data\n",
        "        # -------------------------\n",
        "        Y_pred = model.predict(X_test, verbose=0)\n",
        "        Y_pred_binary = np.round(Y_pred).flatten()\n",
        "\n",
        "        accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
        "        precision = precision_score(Y_test, Y_pred_binary, zero_division=0)\n",
        "        recall = recall_score(Y_test, Y_pred_binary, zero_division=0)\n",
        "        f1 = f1_score(Y_test, Y_pred_binary, zero_division=0)\n",
        "        mcc = matthews_corrcoef(Y_test, Y_pred_binary)\n",
        "\n",
        "        try:\n",
        "            auc_roc = roc_auc_score(Y_test, Y_pred)\n",
        "        except:\n",
        "            auc_roc = 0.5\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "        mcc_scores.append(mcc)\n",
        "        auc_roc_scores.append(auc_roc)\n",
        "\n",
        "        print(f\"   Accuracy: {accuracy:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "        fold_number += 1\n",
        "\n",
        "    # -------------------------\n",
        "    # 8. Print averages\n",
        "    # -------------------------\n",
        "    print(\"\\n\" + \"-\" * 30)\n",
        "    print(\"Average Test Accuracy:\", np.mean(accuracy_scores))\n",
        "    print(\"Average Precision:\", np.mean(precision_scores))\n",
        "    print(\"Average Recall:\", np.mean(recall_scores))\n",
        "    print(\"Average F1 Score:\", np.mean(f1_scores))\n",
        "    print(\"Average MCC:\", np.mean(mcc_scores))\n",
        "    print(\"Average AUC-ROC:\", np.mean(auc_roc_scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure X, Y are numpy arrays (no global scaling!)\n",
        "X_arr = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
        "Y_arr = Y.values if isinstance(Y, (pd.Series, np.ndarray)) else np.asarray(Y)\n",
        "\n",
        "# Call the leak-free k-fold function\n",
        "kfold_fixed(\n",
        "    X_arr,\n",
        "    Y_arr,\n",
        "    filter_size=filter_size,\n",
        "    number_of_filter=number_of_filter,\n",
        "    flatten_layer_exist=flatten_layer_exist,\n",
        "    Model_Name=Model_Name,\n",
        "    OverSamplingTecnique=OverSamplingTecnique\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQn6SrY8EjYF",
        "outputId": "204128b7-f905-43ec-b777-16a54017dcd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying K-fold (Leak-Free)\n",
            "Applying 128 filters of size 5\n",
            "\n",
            "Fold 1/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8740 | F1: 0.5828\n",
            "\n",
            "Fold 2/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8240 | F1: 0.5368\n",
            "\n",
            "Fold 3/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8620 | F1: 0.6425\n",
            "\n",
            "Fold 4/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8980 | F1: 0.6667\n",
            "\n",
            "Fold 5/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8940 | F1: 0.6826\n",
            "\n",
            "Fold 6/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8660 | F1: 0.6171\n",
            "\n",
            "Fold 7/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8920 | F1: 0.6786\n",
            "\n",
            "Fold 8/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8920 | F1: 0.6197\n",
            "\n",
            "Fold 9/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.8700 | F1: 0.6199\n",
            "\n",
            "Fold 10/10\n",
            "   Resampling training data with SMOTE...\n",
            "   Accuracy: 0.9000 | F1: 0.6667\n",
            "\n",
            "------------------------------\n",
            "Average Test Accuracy: 0.8772\n",
            "Average Precision: 0.5577465474180181\n",
            "Average Recall: 0.7397786720321932\n",
            "Average F1 Score: 0.6313394309230292\n",
            "Average MCC: 0.5713707278507549\n",
            "Average AUC-ROC: 0.8735919052560062\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}